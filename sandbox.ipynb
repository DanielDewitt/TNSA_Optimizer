{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astra import Astra\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import CMethods\n",
    "import scipy.constants as const\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12,8)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "A0 = Astra(\"astra.in\")\n",
    "\n",
    "b_field = 10\n",
    "A0.input['solenoid']['MaxB(1)'] = b_field\n",
    "A0.input['newrun']['zstop'] = 0.6\n",
    "A0.input['aperture']['lapert'] = False\n",
    "A0.input['aperture']['Ap_Z1(1)'] = 0.04\n",
    "A0.input['aperture']['Ap_Z2(1)'] = 0.34\n",
    "A0.timeout = None\n",
    "A0.verbose = True\n",
    "\n",
    "#Run\n",
    "A0.run()\n",
    "A0.plot()\n",
    "A0.plot(['norm_emit_x', 'norm_emit_y'], xlim = (0, 10), figsize=(15,8) )\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output_particles = A0.output[\"particles\"][-1]\n",
    "\n",
    "A1 = Astra(\"astra.in\")\n",
    "\n",
    "b_field = 5\n",
    "\n",
    "\n",
    "A1.input['solenoid']['MaxB(1)'] = b_field\n",
    "A1.input['solenoid']['S_pos(1)'] = 2\n",
    "\n",
    "A1.input['aperture']['lapert'] = False\n",
    "A1.input['aperture']['Ap_Z1(1)'] = 2.04\n",
    "A1.input['aperture']['Ap_Z2(1)'] = 2.34\n",
    "\n",
    "A1.verbose = True\n",
    "A1.track(output_particles,2.5)\n",
    "\n",
    "particles = A1.output[\"particles\"][-1]\n",
    "\n",
    "print(particles[\"x\"])\n",
    "print(particles[\"mean_y\"])\n",
    "\n",
    "A1.plot()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd1d8a2fb758a6b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "cmap = matplotlib.colormaps.get_cmap('inferno')\n",
    "\n",
    "skip=1\n",
    "X = np.array([P0.x for P0 in  A0.particles]).T[::skip]\n",
    "Y = np.array([P0.y for P0 in  A0.particles]).T[::skip]\n",
    "Z = np.array([P0.z for P0 in  A0.particles]).T[::skip]\n",
    "\n",
    "scale = np.hypot(X[:, 0], Y[:,0]).max()\n",
    "\n",
    "# color by  initial radius\n",
    "for i in range(len(X)):\n",
    "    color = cmap(1-np.hypot(X[i,0], Y[i,0])/scale)\n",
    "    ax.plot(X[i]*1e3, Y[i]*1e3, Z[i], zdir='x', color=color, linewidth=.3)\n",
    "\n",
    "ax.set_box_aspect((2,1,1))    \n",
    "    \n",
    "ax.set_xlabel('Z (m)')\n",
    "ax.set_ylabel('X (mm)')\n",
    "ax.set_zlabel('Y (mm)')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad8d9040ac40c73e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "cmap = matplotlib.colormaps.get_cmap('inferno')\n",
    "\n",
    "skip=1\n",
    "X = np.array([P0.x for P0 in  A1.particles]).T[::skip]\n",
    "Y = np.array([P0.y for P0 in  A1.particles]).T[::skip]\n",
    "Z = np.array([P0.z for P0 in  A1.particles]).T[::skip]\n",
    "\n",
    "scale = np.hypot(X[:, 0], Y[:,0]).max()\n",
    "\n",
    "# color by  initial radius\n",
    "for i in range(len(X)):\n",
    "    color = cmap(1-np.hypot(X[i,0], Y[i,0])/scale)\n",
    "    ax.plot(X[i]*1e3, Y[i]*1e3, Z[i], zdir='x', color=color, linewidth=.3)\n",
    "\n",
    "ax.set_box_aspect((2,1,1))    \n",
    "    \n",
    "ax.set_xlabel('Z (m)')\n",
    "ax.set_ylabel('X (mm)')\n",
    "ax.set_zlabel('Y (mm)')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0b5ba088833c5be",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from astra import Astra\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def toy_model(b_0, b_1, d_0, d_1):\n",
    "    \n",
    "    print(b_0, b_1, d_0, d_1)\n",
    "\n",
    "    z_end = 5.4                                 #end position of simulation, e.g. diagnostics\n",
    "    z_0 = 0.04                                  #position of the first element\n",
    "\n",
    "    l_sol = 0.3                                 #solenoid length\n",
    "    d_buffer = 0.2                              #buffer between elements\n",
    "\n",
    "    z_seg_0 = z_0 + d_0 + l_sol + d_buffer      #length of the first simulation segment\n",
    "    z_seg_1 = d_1 + l_sol\n",
    "    z_seg_12 = z_seg_0 + z_seg_1\n",
    "    z_rem = z_end - z_seg_12\n",
    "\n",
    "    #Configure first solenoid\n",
    "\n",
    "    A0 = Astra(\"astra.in\")\n",
    "\n",
    "    A0.input['aperture']['lapert'] = False\n",
    "    A0.input['aperture']['Ap_Z1(1)'] = z_0+d_0\n",
    "    A0.input['aperture']['Ap_Z2(1)'] = z_0+d_0+l_sol\n",
    "\n",
    "    A0.input['solenoid']['MaxB(1)'] = b_0\n",
    "\n",
    "    A0.input['newrun']['zstart'] = 0\n",
    "    A0.input['newrun']['zstop'] = z_seg_0\n",
    "    output_particles_0 = None\n",
    "\n",
    "    try:\n",
    "        if z_rem > 0:\n",
    "            A0.run()\n",
    "            output_particles_0 = A0.output[\"particles\"][-1]\n",
    "        else:\n",
    "            sigma_x = 0\n",
    "            sigma_y = 0\n",
    "            dx = 0\n",
    "            dy = 0\n",
    "\n",
    "    except ValueError:\n",
    "        sigma_x = 0\n",
    "        sigma_y = 0\n",
    "        dx = 0\n",
    "        dy = 0\n",
    "\n",
    "    A1 = Astra(\"astra.in\")\n",
    "    A1.input['aperture']['lapert'] = False\n",
    "    A1.input['aperture']['Ap_Z1(1)'] = z_seg_0 + d_1\n",
    "    A1.input['aperture']['Ap_Z2(1)'] = z_seg_0 + d_1 + l_sol\n",
    "\n",
    "    A1.input['solenoid']['MaxB(1)'] = b_1\n",
    "\n",
    "    A1.input['newrun']['zstart'] = z_seg_0\n",
    "    A1.input['newrun']['zstop'] = z_end\n",
    "\n",
    "    try:\n",
    "        if z_rem > 0:\n",
    "            A1.track(output_particles_0,2.5)\n",
    "            output_particles_1 = A1.output[\"particles\"][-1]\n",
    "            sigma_x = output_particles_1[\"x\"]\n",
    "            sigma_y = output_particles_1[\"y\"]\n",
    "        else:\n",
    "            sigma_x = 0\n",
    "            sigma_y = 0\n",
    "            dx = 0\n",
    "            dy = 0\n",
    "\n",
    "    except ValueError:\n",
    "        sigma_x = 0\n",
    "        sigma_y = 0\n",
    "        dx = 0\n",
    "        dy = 0\n",
    "        \n",
    "    except UnboundLocalError:\n",
    "        sigma_x = 0\n",
    "        sigma_y = 0\n",
    "        dx = 0\n",
    "        dy = 0\n",
    "    \n",
    "    return sigma_x, sigma_y\n",
    "\n",
    "\n",
    "class AstraOptimizer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        # register set of quad strengths as parameter:\n",
    "        self.register_parameter('params',torch.nn.Parameter(params, requires_grad=True))\n",
    "\n",
    "    def forward(self):\n",
    "        # create lattice given quad strengths in k_set:\n",
    "        sigma = toy_model(self.params[0].item(), self.params[1].item(), self.params[2].item(), self.params[3].item())\n",
    "        try:\n",
    "            sigma_x = torch.std(torch.tensor(sigma[0]))\n",
    "            sigma_y = torch.std(torch.tensor(sigma[1]))\n",
    "            print(sigma_x, sigma_y)\n",
    "        except TypeError:\n",
    "            sigma_x = torch.zeros(1)\n",
    "            sigma_y = torch.zeros(1)\n",
    "\n",
    "        sigma_target = 0.0001# calculate and return loss function:\n",
    "        dx = (sigma_x - sigma_target)\n",
    "        dy = (sigma_y - sigma_target)\n",
    "        \n",
    "        #hier add zu sqrt\n",
    "        return torch.add(dx ** 2 + dy ** 2)\n",
    "\n",
    "\n",
    "def train_model(model, training_iter, alpha=0.1):\n",
    "    history_param = [None] * training_iter  # list to save params\n",
    "    history_loss = [None] * training_iter  # list to save loss\n",
    "\n",
    "    # print the trainable parameters\n",
    "    for param in model.named_parameters():\n",
    "        print(f'{param[0]} : {param[1]}')\n",
    "\n",
    "    # Use PyTorch Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), alpha)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = model()  # loss is just O.F.\n",
    "        #loss.requires_grad = True\n",
    "        loss.backward()  # gradient\n",
    "\n",
    "        # print info:\n",
    "        if i % 100 == 0:  # print each 100 steps\n",
    "            print('Iter %d/%d - Loss: %.5f ' % (\n",
    "                i + 1, training_iter, loss\n",
    "            ))\n",
    "\n",
    "        # save loss and param\n",
    "        for param in model.parameters():\n",
    "            history_param[i] = param.data.detach().numpy().copy()\n",
    "        history_loss[i] = loss.detach().numpy().copy()\n",
    "\n",
    "        # optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "    # returns params and loss for every iteration\n",
    "    return np.asarray(history_param), np.asarray(history_loss)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5fd4f5c82052329",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "k_set = torch.zeros(4)\n",
    "\n",
    "# Optimization\n",
    "model = AstraOptimizer(k_set)\n",
    "params, loss = train_model(model, 1000, 0.01)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ceeb25e5ae3a5bc5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(torch.backends.mps.is_available())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acbb785be70decf9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "k_0 = torch.tensor(3)\n",
    "k_1 = torch.tensor(2)\n",
    "k = torch.div(k_0, k_1)\n",
    "print(torch.sin(torch.mul(k_0,k_1)))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fed4ec6929f0328",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9500f9d9560a9da5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531\n",
      "tensor([[-4.1014e-05, -1.8698e-01, -1.2264e-05, -5.5894e-02,  0.0000e+00,\n",
      "         -8.0249e-02],\n",
      "        [-1.8987e-06, -8.6527e-03,  1.2288e-05,  5.5999e-02,  0.0000e+00,\n",
      "         -8.0210e-02],\n",
      "        [-8.0363e-06, -3.6624e-02,  4.0598e-05,  1.8508e-01,  0.0000e+00,\n",
      "         -8.0246e-02],\n",
      "        ...,\n",
      "        [ 2.3463e-06,  1.0693e-02, -6.1445e-06, -2.8002e-02,  0.0000e+00,\n",
      "         -8.0207e-02],\n",
      "        [-2.5910e-06, -1.1808e-02,  4.2457e-05,  1.9356e-01,  0.0000e+00,\n",
      "         -8.0248e-02],\n",
      "        [-6.4207e-06, -2.9261e-02,  1.6722e-05,  7.6210e-02,  0.0000e+00,\n",
      "         -8.0214e-02]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import CMethods\n",
    "import torch\n",
    "import numpy as np\n",
    "test_particles_xyz = CMethods.astra_file_to_ttm(\"test_plasma_file_protons.part\", 10, \"proton\")\n",
    "\n",
    "print(test_particles_xyz.size(0))\n",
    "x = torch.empty(0,6)\n",
    "y =torch.tensor([1,2,3,4,5,6])\n",
    "if x.size(0) == 0:\n",
    "    x = y\n",
    "else:\n",
    "    x = torch.stack((x, y),0)\n",
    "\n",
    "y =torch.tensor([1,2,3,4,5,6])\n",
    "if x.size(0) == 0:\n",
    "    x = y\n",
    "else:\n",
    "    x = torch.stack((x, y),0)\n",
    "    \n",
    "\n",
    "\n",
    "print(test_particles_xyz)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T16:12:54.998194Z",
     "start_time": "2024-05-16T16:12:52.948883Z"
    }
   },
   "id": "96c825f558682887",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import elements\n",
    "\n",
    "def toy_model(b_0, b_1, d_0, d_1):\n",
    "    \n",
    "    print(b_0, b_1, d_0, d_1)\n",
    "    \n",
    "    segments = 100\n",
    "\n",
    "    z_end = 5.4                                 #end position of simulation\n",
    "    z_0 = 0.04\n",
    "    \n",
    "    ref_energy = 10\n",
    "\n",
    "    l_sol = torch.tensor(0.3, requires_grad=True)                                 #solenoid length\n",
    "    #d_buffer = 0.2                              #buffer between elements\n",
    "    \n",
    "    drift_0 = elements.Drift(segments, z_0, ref_energy)\n",
    "    drift_1 = elements.Drift(segments, d_0, ref_energy)\n",
    "    solenoid_0 = elements.Solenoid(segments, b_field=b_0, length=l_sol, ref_energy=ref_energy)\n",
    "    drift_2 = elements.Drift(segments, d_1, ref_energy)\n",
    "    solenoid_1 = elements.Solenoid(segments, b_field=b_1, length=l_sol, ref_energy=ref_energy)\n",
    "    \n",
    "    z_rem = z_end - (z_0+d_0+2*l_sol+d_1)\n",
    "    \n",
    "    drift_3 = elements.Drift(segments, z_rem, ref_energy)\n",
    "    \n",
    "    toy_list = [drift_0, drift_1, solenoid_0, drift_2, solenoid_1, drift_3]\n",
    "\n",
    "    \n",
    "    beamline_0 = elements.Beamline()\n",
    "\n",
    "\n",
    "#    if z_rem > 0:\n",
    "#        [output_parts, rms] = beamline_0.track(element_list=toy_list, input_particles=test_particles_xyz)\n",
    "#        sigma_x = rms[0][-1].item()\n",
    "#        sigma_y = rms[1][-1].item()\n",
    "#    else:\n",
    "#        sigma_x = 0\n",
    "#        sigma_y = 0\n",
    "#        dx = 0\n",
    "#        dy = 0\n",
    "    [output_parts, rms] = beamline_0.track(element_list=toy_list, input_particles=test_particles_xyz)\n",
    "    return rms\n",
    "\n",
    "class AstraOptimizer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, par):\n",
    "        super().__init__()\n",
    "        # register set of parameter:\n",
    "        self.register_parameter('par',torch.nn.Parameter(par, requires_grad=True))\n",
    "\n",
    "    def forward(self):\n",
    "        # create lattice given quad strengths in k_set:\n",
    "        rms = toy_model(self.par[0], self.par[1], self.par[2], self.par[3])\n",
    "        \n",
    "        #sigma_x = torch.std(rms[-1][:, 0].clone())\n",
    "        #sigma_y = torch.std(rms[-1][:, 2].clone())\n",
    "        sigma_x = torch.std(rms[-1].clone())\n",
    "        sigma_y = torch.std(rms[-1].clone())\n",
    "\n",
    "        #sigma_target = torch.tensor(0.0001, dtype=torch.float64)# calculate and return loss function:\n",
    "        sigma_target = 0.001\n",
    "        dx = (sigma_x - sigma_target)\n",
    "        dy = (sigma_y - sigma_target)\n",
    "\n",
    "        return torch.sqrt(torch.add(torch.square(dx), torch.square(dy)))\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, training_iter, alpha=0.1):\n",
    "    history_param = [None] * training_iter  # list to save params\n",
    "    history_loss = [None] * training_iter  # list to save loss\n",
    "\n",
    "    # print the trainable parameters\n",
    "    for param in model.named_parameters():\n",
    "        print(f'{param[0]} : {param[1]}')\n",
    "\n",
    "    # Use PyTorch Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), alpha)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "    \n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Calc loss and backprop gradients\n",
    "        #with torch.autograd.detect_anomaly():\n",
    "        loss = model()  # loss is just O.F.\n",
    "        loss.backward()  # gradient#\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print info:\n",
    "        if i % 10 == 0:  # print each 100 steps\n",
    "            print('Iter %d/%d - Loss: %.5f ' % (\n",
    "                i + 1, training_iter, loss\n",
    "            ))\n",
    "\n",
    "        # save loss and param\n",
    "        #for param in model.parameters():\n",
    "        #    history_param[i] = param.data.detach().numpy().copy()\n",
    "        #history_loss[i] = loss.detach().numpy().copy()\n",
    "\n",
    "        # optimization step\n",
    "        \n",
    "\n",
    "    # returns params and loss for every iteration\n",
    "    return np.asarray(history_param), np.asarray(history_loss)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T16:50:39.374541Z",
     "start_time": "2024-05-16T16:50:39.158614Z"
    }
   },
   "id": "7a54129abd5ac7f0",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "par : Parameter containing:\n",
      "tensor([3., 2., 2., 2.], dtype=torch.float64, requires_grad=True)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 1/1000 - Loss: 2.57778 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0000, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0000, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.0684, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.0186, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.4421, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8323, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.4318, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.3894, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.1203, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.6395, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.3553, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.6531, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9098, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.5118, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.4627, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.2940, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.9186, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0769, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2.2002, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9229, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 11/1000 - Loss: 1.73416 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2.2889, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8624, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2.2092, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8958, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2.0012, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0030, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.7093, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.1514, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.3812, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.2993, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0672, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.4038, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.8122, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.4327, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.6451, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.3736, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.5741, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.2335, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.5896, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0339, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 21/1000 - Loss: 1.63342 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.6695, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8064, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.7845, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.5891, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9032, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.4198, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9988, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.3271, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0548, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.3234, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0669, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.4041, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0423, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.5511, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9969, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.7371, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9513, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9296, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9255, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0966, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 31/1000 - Loss: 1.61136 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9333, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.2134, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9791, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.2672, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0571, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.2588, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1529, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.2007, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.2468, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.1129, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.3185, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0187, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.3518, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9389, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.3386, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8877, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.2811, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8699, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1902, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8811, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 41/1000 - Loss: 1.60668 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0837, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9097, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9819, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9407, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9033, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9601, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.8602, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9588, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.8566, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9352, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.8879, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8948, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9426, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8487, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0058, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8104, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0629, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.7917, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1028, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.7995, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 51/1000 - Loss: 1.60656 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1209, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8338, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1187, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8878, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1032, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9497, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0836, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0058, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0690, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0442, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0650, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0577, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0728, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0454, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0887, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-1.0127, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1060, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9692, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1174, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9260, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 61/1000 - Loss: 1.60444 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1170, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8928, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1028, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8754, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0770, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8745, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0454, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.8861, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0160, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9037, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9960, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9201, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9902, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9298, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(0.9996, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9308, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0209, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9246, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0484, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9155, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 71/1000 - Loss: 1.60413 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0747, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9086, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0940, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9080, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1028, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9154, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.1009, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9295, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0911, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9464, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0781, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9609, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0664, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9687, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0592, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9671, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0575, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9567, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0602, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9403, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 81/1000 - Loss: 1.60413 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0643, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9225, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0670, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9081, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0661, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9004, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0613, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9005, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0540, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9071, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0469, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9172, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0427, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9273, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0432, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9344, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0488, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9372, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0580, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9360, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 91/1000 - Loss: 1.60412 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0682, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9326, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0765, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9293, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0808, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9279, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0802, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9292, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0756, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9324, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0686, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9361, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0617, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9384, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0568, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9379, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0549, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9344, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0557, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9289, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "Iter 101/1000 - Loss: 1.60412 \n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0580, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9229, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0606, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9185, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0621, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9170, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0620, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9186, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0608, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9227, dtype=torch.float64, grad_fn=<SelectBackward0>)\n",
      "tensor(3., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(2., dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(1.0594, dtype=torch.float64, grad_fn=<SelectBackward0>) tensor(-0.9278, dtype=torch.float64, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Optimization\u001B[39;00m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m AstraOptimizer(k_set)\n\u001B[0;32m----> 6\u001B[0m params, loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[10], line 87\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, training_iter, alpha)\u001B[0m\n\u001B[1;32m     84\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     85\u001B[0m \u001B[38;5;66;03m# Calc loss and backprop gradients\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;66;03m#with torch.autograd.detect_anomaly():\u001B[39;00m\n\u001B[0;32m---> 87\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# loss is just O.F.\u001B[39;00m\n\u001B[1;32m     88\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# gradient#\u001B[39;00m\n\u001B[1;32m     89\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TNSA_Optimizer/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/TNSA_Optimizer/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[10], line 54\u001B[0m, in \u001B[0;36mAstraOptimizer.forward\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;66;03m# create lattice given quad strengths in k_set:\u001B[39;00m\n\u001B[0;32m---> 54\u001B[0m     rms \u001B[38;5;241m=\u001B[39m \u001B[43mtoy_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpar\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpar\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpar\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpar\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;66;03m#sigma_x = torch.std(rms[-1][:, 0].clone())\u001B[39;00m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;66;03m#sigma_y = torch.std(rms[-1][:, 2].clone())\u001B[39;00m\n\u001B[1;32m     58\u001B[0m     sigma_x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstd(rms[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mclone())\n",
      "Cell \u001B[0;32mIn[10], line 42\u001B[0m, in \u001B[0;36mtoy_model\u001B[0;34m(b_0, b_1, d_0, d_1)\u001B[0m\n\u001B[1;32m     30\u001B[0m     beamline_0 \u001B[38;5;241m=\u001B[39m elements\u001B[38;5;241m.\u001B[39mBeamline()\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m#    if z_rem > 0:\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m#        [output_parts, rms] = beamline_0.track(element_list=toy_list, input_particles=test_particles_xyz)\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m#        sigma_x = rms[0][-1].item()\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m#        dx = 0\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m#        dy = 0\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m     [output_parts, rms] \u001B[38;5;241m=\u001B[39m \u001B[43mbeamline_0\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoy_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_particles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_particles_xyz\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m rms\n",
      "File \u001B[0;32m~/Desktop/Simulationen/git/TNSA_Optimizer/TNSA_Optimizer/elements.py:304\u001B[0m, in \u001B[0;36mBeamline.track\u001B[0;34m(self, element_list, input_particles)\u001B[0m\n\u001B[1;32m    302\u001B[0m         [output_particles, output_rms] \u001B[38;5;241m=\u001B[39m element\u001B[38;5;241m.\u001B[39mtrack(input_particles)\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 304\u001B[0m         [output_particles, output_rms] \u001B[38;5;241m=\u001B[39m \u001B[43melement\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_particles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_rms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    306\u001B[0m     i \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [output_particles, output_rms]\n",
      "File \u001B[0;32m~/Desktop/Simulationen/git/TNSA_Optimizer/TNSA_Optimizer/elements.py:85\u001B[0m, in \u001B[0;36mBeamLineElement.track\u001B[0;34m(self, input_particles, rms, second_order)\u001B[0m\n\u001B[1;32m     81\u001B[0m     working_particles \u001B[38;5;241m=\u001B[39m output_bunch\u001B[38;5;241m.\u001B[39mclone()\n\u001B[1;32m     83\u001B[0m     rms[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([rms[\u001B[38;5;241m0\u001B[39m], torch\u001B[38;5;241m.\u001B[39mstd(output_bunch[:, \u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)])\n\u001B[0;32m---> 85\u001B[0m     rms[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([rms[\u001B[38;5;241m1\u001B[39m], \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstd\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_bunch\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)])\n\u001B[1;32m     87\u001B[0m     rms[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([rms[\u001B[38;5;241m2\u001B[39m], torch\u001B[38;5;241m.\u001B[39mmul(torch\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz_start, torch\u001B[38;5;241m.\u001B[39mmul(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_length, i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)), torch\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;241m1\u001B[39m, requires_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))])\n\u001B[1;32m     89\u001B[0m input_particles_temp\u001B[38;5;241m.\u001B[39mappend(output_bunch)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "k_set = torch.tensor([3, 2, 2, 2], requires_grad=True, dtype=torch.float64)\n",
    "\n",
    "# Optimization\n",
    "model = AstraOptimizer(k_set)\n",
    "\n",
    "params, loss = train_model(model, 1000, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T17:00:24.414023Z",
     "start_time": "2024-05-16T17:00:19.329357Z"
    }
   },
   "id": "44d4e4e38c974526",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "[x,y,z] = elements.toy_model(4.235, 2, 0, 4, test_particles_xyz)\n",
    "\n",
    "rms_plt_test = [x.clone(), y.clone(), z.clone()]\n",
    "\n",
    "plt.plot(rms_plt_test[2].detach().clone(), rms_plt_test[0].detach().clone())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9cd203d7fddc471",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "b = torch.tensor([5,6,7,8])\n",
    "\n",
    "tensor_list = [a, b]\n",
    "\n",
    "if isinstance(a, torch.Tensor):\n",
    "    a_list = [a]\n",
    "else:\n",
    "    a_list = a\n",
    "\n",
    "\n",
    "a_list.append(b)\n",
    "\n",
    "\n",
    "print(a_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c15573697a781ba",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4e588c90f9d0de55"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
